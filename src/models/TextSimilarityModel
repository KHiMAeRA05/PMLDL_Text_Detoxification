import torch
from transformers import DistilBertTokenizer, DistilBertModel
from sklearn.metrics.pairwise import cosine_similarity

class TextSimilarityModel:
    def __init__(self, model_name='distilbert-base-uncased'):
        self.tokenizer = DistilBertTokenizer.from_pretrained(model_name)
        self.model = DistilBertModel.from_pretrained(model_name)

    def calculate_similarity(self, text1, text2):
        input_ids1 = self.tokenizer(text1, return_tensors='pt').input_ids
        input_ids2 = self.tokenizer(text2, return_tensors='pt').input_ids
        with torch.no_grad():
            emb1 = self.model(input_ids1).last_hidden_state[:, 0, :]
            emb2 = self.model(input_ids2).last_hidden_state[:, 0, :]
        return cosine_similarity(emb1, emb2)

    def predict(self, text1, text2):
        similarity_score = self.calculate_similarity(text1, text2)[0][0]
        return similarity_score

# Example usage

# # Create an instance of the TextSimilarityModel
# similarity_model = TextSimilarityModel()